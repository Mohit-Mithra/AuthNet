# Authnet

AUTHNET - A deep learning based authentication mechanism using temporal facial feature movements <br>

Face recognition systems are typically based on a still image of a face picture and comparing it with the previous data to make predictions. The aim of the project is to develop a face recognition model that can strengthen the existing system by making use of facial movement patterns. It involves training the system on videos of the user uttering a predetermined password. Once that is done, the system can identify if a video of a person uttering a word is the correct person saying the correct password or not. 

This can be used as a facial recognition system, where the system “recognises” the right person uttering the right password.

Find our paper on arxiv: <https://arxiv.org/abs/2012.02515> <br>
<br>

You will need need to add a 'Utilities' folder structure and add the following files: <br>
-> white.jpg (white image for padding) <br>
-> Download the VGGface.h5 file from here ([VGGFace](https://drive.google.com/file/d/1cgNbT4UOGyEiAcB64vqwkhNtp-XCsL3u/view?usp=sharing)) <br>
<br>

# AuthNet has been accepted into AAAI-21 student abstract and poster program for oral presentation. <br>
<br>
<br>
Cite us: <br>
@misc{raghavendra2020authnet, <br>
      title={AuthNet: A Deep Learning based Authentication Mechanism using Temporal Facial Feature Movements}, <br>
      author={Mohit Raghavendra and Pravan Omprakash and B R Mukesh and Sowmya Kamath}, <br>
      year={2020}, <br>
      eprint={2012.02515}, <br>
      archivePrefix={arXiv}, <br>
      primaryClass={cs.CV} <br>
}
