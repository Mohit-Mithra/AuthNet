{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format( 'channels_last' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convblock(cdim, nb, bits=3):  #define repeating layers og VGGNet at a block\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        #L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) ) # Keras 1\n",
    "        L.append( Convolution2D(cdim, kernel_size=(3, 3), padding='same', activation='relu', name=convname) ) # Keras 2\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_face_blank(): #define VGGFace model\n",
    "    \n",
    "    withDO = True \n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        mdl.add( Permute((1,2,3), input_shape=(224,224,3)) ) #0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        \n",
    "        mdl.add( Convolution2D(4096, kernel_size=(7, 7), activation='relu', name='fc6') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "       \n",
    "        mdl.add( Convolution2D(4096, kernel_size=(1, 1), activation='relu', name='fc7') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "      \n",
    "        mdl.add( Convolution2D(2622, kernel_size=(1, 1), activation='relu', name='fc8') ) # Keras 2\n",
    "        mdl.add( Flatten() )\n",
    "        mdl.add( Activation('softmax') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "facemodel = vgg_face_blank() #define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat #import weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = loadmat('C:\\\\Users\\\\Om\\\\Desktop\\\\vgg-face.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    l = data['layers']\n",
    "    description = data['meta'][0,0].classes[0,0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l.shape, description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l[0,10][0,0].type[0], l[0,10][0,0].name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_compare(kmodel): #convert weights from MATLAB to python format\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "    prmt = (0,1,2,3) \n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        mattype = l[0,i][0,0].type[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            print(matname, mattype)\n",
    "            print(l[0,i][0,0].weights[0,0].transpose(prmt).shape, l[0,i][0,0].weights[0,1].shape)\n",
    "            print(kmodel.layers[kindex].get_weights()[0].shape, kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            print('------------------------------------------')\n",
    "        else:\n",
    "            print('MISSING : ', matname, mattype)\n",
    "            print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_mat_to_keras(kmodel):\n",
    "\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "    prmt = (0,1,2,3)\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            \n",
    "            l_weights = l[0,i][0,0].weights[0,0]\n",
    "            l_bias = l[0,i][0,0].weights[0,1]\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Om\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "copy_mat_to_keras(facemodel) #load weights into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuremodel = Model(inputs=facemodel.layers[0].input, outputs=facemodel.layers[-1].output) #drop softmax layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image cropping for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(np.asarray(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def pred(kmodel, crpimg, transform=False):\n",
    "    \n",
    "    # transform=True seems more robust but I think the RGB channels are not in right order\n",
    "    \n",
    "    imarr = np.array(crpimg).astype(np.float32)\n",
    "\n",
    "    if transform:\n",
    "        imarr[:,:,0] -= 129.1863\n",
    "        imarr[:,:,1] -= 104.7624\n",
    "        imarr[:,:,2] -= 93.5940\n",
    "        #\n",
    "        # WARNING : in this script (https://github.com/rcmalli/keras-vggface) colours are switched\n",
    "        aux = copy.copy(imarr)\n",
    "        #imarr[:, :, 0] = aux[:, :, 2]\n",
    "        #imarr[:, :, 2] = aux[:, :, 0]\n",
    "\n",
    "        #imarr[:,:,0] -= 129.1863\n",
    "        #imarr[:,:,1] -= 104.7624\n",
    "        #imarr[:,:,2] -= 93.5940\n",
    "\n",
    "    #imarr = imarr.transpose((2,0,1)) # INFO : for 'th' setting of 'dim_ordering'\n",
    "    imarr = np.expand_dims(imarr, axis=0)\n",
    "\n",
    "    out = kmodel.predict(imarr)\n",
    "\n",
    "    best_index = np.argmax(out, axis=1)[0]\n",
    "    best_name = description[best_index,0]\n",
    "    print(best_index, best_name[0], out[0,best_index], [np.min(out), np.max(out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(featmodel, crpimg, transform=False): #extract face feature vector\n",
    "    \n",
    "    # transform=True seems more robust but I think the RGB channels are not in right order\n",
    "    \n",
    "    imarr = np.array(crpimg).astype(np.float32)\n",
    "\n",
    "    if transform:\n",
    "        imarr[:,:,0] -= 129.1863\n",
    "        imarr[:,:,1] -= 104.7624\n",
    "        imarr[:,:,2] -= 93.5940        \n",
    "        aux = copy.copy(imarr)\n",
    "    imarr = np.expand_dims(imarr, axis=0)\n",
    "\n",
    "    fvec = featmodel.predict(imarr)[0,:]\n",
    "    # normalize\n",
    "    normfvec = math.sqrt(fvec.dot(fvec))\n",
    "    return fvec/normfvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting face features of positive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[0]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[0]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "for utterance in lwordFolder:\n",
    "    j += 1\n",
    "    utterFolder= '%s\\\\%s' % (wordFolder,utterance)\n",
    "    lutterFolder = os.listdir(utterFolder)\n",
    "    #print(lutterFolder)\n",
    "    colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "    lcolourFolder = os.listdir(colourFolder)\n",
    "    i=0\n",
    "    for frame in lcolourFolder:\n",
    "        i += 1\n",
    "        image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "        im=Image.open(image)\n",
    "        im = im.resize((224,224))\n",
    "        feature_vector = features(featuremodel,im, transform=True)\n",
    "        #print(feature_vector.shape)\n",
    "        feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "        if i==1 :\n",
    "            feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "        else:\n",
    "            feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "    print(j)\n",
    "    if j == 1:\n",
    "        sample_space=feature_sequence\n",
    "    else:\n",
    "        sample_space=np.concatenate((sample_space,feature_sequence))\n",
    "    if j==9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[[[6.75963690e-07 8.25880124e-06 1.11793170e-05 ... 4.66088778e-07\n",
      "   5.59341206e-05 1.89274695e-04]\n",
      "  [3.68687834e-05 3.32745840e-05 2.26098364e-05 ... 2.38872030e-06\n",
      "   4.72466258e-04 2.51124118e-04]\n",
      "  [2.25483982e-05 6.61253989e-06 5.48863463e-05 ... 2.88070873e-06\n",
      "   1.88437087e-04 1.87333702e-04]\n",
      "  ...\n",
      "  [7.30168085e-06 7.31176397e-06 3.40432707e-05 ... 9.35737035e-07\n",
      "   1.06274128e-04 1.38831048e-04]\n",
      "  [2.87230250e-05 4.04849852e-05 1.27139632e-04 ... 6.01278862e-06\n",
      "   4.72722022e-04 4.73145512e-04]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]\n",
      "\n",
      " [[1.21957986e-04 4.71811436e-05 3.15443234e-04 ... 9.53527524e-06\n",
      "   5.55832498e-03 1.44382613e-03]\n",
      "  [1.36644085e-04 5.08134399e-05 3.36446741e-04 ... 1.32323767e-05\n",
      "   3.96228861e-04 4.30966448e-03]\n",
      "  [1.29346838e-04 2.83445770e-05 6.78209937e-04 ... 7.15792976e-06\n",
      "   1.15853458e-04 2.36908044e-03]\n",
      "  ...\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]\n",
      "\n",
      " [[3.63496001e-05 7.40701362e-05 2.74509308e-04 ... 3.11012627e-06\n",
      "   3.75319127e-04 1.79252413e-03]\n",
      "  [8.51692130e-06 5.08713856e-05 5.51762569e-05 ... 6.54790711e-07\n",
      "   1.49875661e-04 5.60128014e-04]\n",
      "  [1.42840017e-05 9.89369510e-05 6.37862177e-05 ... 1.00465854e-06\n",
      "   2.16993212e-04 6.59074227e-04]\n",
      "  ...\n",
      "  [1.11458692e-04 1.82139076e-04 8.22738075e-05 ... 5.34135461e-06\n",
      "   1.50124158e-03 1.59184588e-03]\n",
      "  [3.88458466e-05 2.21386363e-05 2.11745224e-04 ... 4.96983102e-06\n",
      "   8.09601974e-04 8.02539289e-04]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.49212314e-05 2.26700984e-04 9.45740612e-05 ... 3.24401708e-06\n",
      "   1.38123671e-03 8.35261308e-03]\n",
      "  [3.01694417e-05 5.03949450e-05 1.88140748e-05 ... 6.44510237e-07\n",
      "   3.40517086e-04 7.31251668e-04]\n",
      "  [3.29050352e-04 9.93865542e-05 3.82309518e-04 ... 1.05786676e-05\n",
      "   6.64002215e-03 7.79698975e-03]\n",
      "  ...\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]\n",
      "\n",
      " [[9.29957532e-05 9.34709824e-05 1.33497801e-04 ... 4.05765923e-06\n",
      "   5.03040559e-04 1.36012735e-03]\n",
      "  [1.19249809e-04 5.69140429e-05 3.76906683e-04 ... 4.29255624e-06\n",
      "   3.51569935e-04 2.24661874e-03]\n",
      "  [1.78502974e-04 4.60528572e-05 5.14292798e-04 ... 9.51003767e-06\n",
      "   2.30365782e-04 1.64792733e-03]\n",
      "  ...\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]\n",
      "\n",
      " [[1.31009685e-04 2.45417963e-04 5.63536945e-04 ... 6.80264338e-06\n",
      "   5.36372885e-04 2.80981860e-03]\n",
      "  [4.97973924e-05 4.69233528e-05 1.19651129e-04 ... 2.61737387e-06\n",
      "   2.28245699e-04 1.61703024e-03]\n",
      "  [2.46043666e-04 1.27868727e-04 6.65041560e-04 ... 1.04688952e-05\n",
      "   1.47158816e-03 3.93680157e-03]\n",
      "  ...\n",
      "  [2.28117322e-04 1.42588731e-04 3.10243660e-04 ... 8.90276533e-06\n",
      "   3.00498074e-03 2.73865834e-03]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]\n",
      "  [4.25673313e-02 6.09404147e-02 1.02217663e-02 ... 6.68874290e-03\n",
      "   2.12680474e-02 2.88120322e-02]]]\n"
     ]
    }
   ],
   "source": [
    "#print(sample_space.shape)\n",
    "sample_space= sample_space.reshape(9,len(lcolourFolder),feature_vector.shape[1]) #input dataset \n",
    "print(sample_space.shape[1])\n",
    "pos_sample_space=sample_space\n",
    "print(pos_sample_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "sample_space_1=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[0]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[1]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "for utterance in lwordFolder:\n",
    "    j += 1\n",
    "    utterFolder= '%s\\\\%s' % (wordFolder,utterance)\n",
    "    lutterFolder = os.listdir(utterFolder)\n",
    "    #print(lutterFolder)\n",
    "    colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "    lcolourFolder = os.listdir(colourFolder)\n",
    "    i=0\n",
    "    for frame in lcolourFolder:\n",
    "        i += 1\n",
    "        image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "        im=Image.open(image)\n",
    "        im = im.resize((224,224))\n",
    "        feature_vector = features(featuremodel,im, transform=True)\n",
    "        #print(feature_vector.shape)\n",
    "        feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "        if i==1 :\n",
    "            feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "        else:\n",
    "            feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "    print(j)\n",
    "    if j == 1:\n",
    "        sample_space_1=feature_sequence\n",
    "    else:\n",
    "        sample_space_1=np.concatenate((sample_space_1,feature_sequence))\n",
    "    if j==9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 8, 2622)\n",
      "(9, 11, 2622)\n",
      "(18, 11, 2622)\n"
     ]
    }
   ],
   "source": [
    "sample_space_2= sample_space_1.reshape(9,len(lcolourFolder),feature_vector.shape[1])\n",
    "print(sample_space_2.shape)\n",
    "sample_space_2=np.concatenate((sample_space_2,np.zeros((9,3,2622))),axis=1)\n",
    "print(sample_space_2.shape)\n",
    "total_sample_space=np.concatenate((pos_sample_space,sample_space_2))\n",
    "print(total_sample_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "sample_space_3=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[6]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[0]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "for utterance in lwordFolder:\n",
    "    j += 1\n",
    "    utterFolder= '%s\\\\%s' % (wordFolder,utterance)\n",
    "    lutterFolder = os.listdir(utterFolder)\n",
    "    #print(lutterFolder)\n",
    "    colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "    lcolourFolder = os.listdir(colourFolder)\n",
    "    i=0\n",
    "    for frame in lcolourFolder:\n",
    "        i += 1\n",
    "        image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "        im=Image.open(image)\n",
    "        im = im.resize((224,224))\n",
    "        feature_vector = features(featuremodel,im, transform=True)\n",
    "        #print(feature_vector.shape)\n",
    "        feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "        if i==1 :\n",
    "            feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "        else:\n",
    "            feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "    print(j)\n",
    "    if j == 1:\n",
    "        sample_space_3=feature_sequence\n",
    "    else:\n",
    "        sample_space_3=np.concatenate((sample_space_3,feature_sequence))\n",
    "    if j==9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 11, 2622)\n",
      "(27, 11, 2622)\n"
     ]
    }
   ],
   "source": [
    "sample_space_4= sample_space_3.reshape(9,len(lcolourFolder),feature_vector.shape[1])\n",
    "print(sample_space_4.shape)\n",
    "total_sample_space1=np.concatenate((total_sample_space,sample_space_4))\n",
    "print(total_sample_space1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "sample_space_5=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[10]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[2]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "for utterance in lwordFolder:\n",
    "    j += 1\n",
    "    utterFolder= '%s\\\\%s' % (wordFolder,utterance)\n",
    "    lutterFolder = os.listdir(utterFolder)\n",
    "    #print(lutterFolder)\n",
    "    colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "    lcolourFolder = os.listdir(colourFolder)\n",
    "    i=0\n",
    "    for frame in lcolourFolder:\n",
    "        i += 1\n",
    "        image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "        im=Image.open(image)\n",
    "        im = im.resize((224,224))\n",
    "        feature_vector = features(featuremodel,im, transform=True)\n",
    "        #print(feature_vector.shape)\n",
    "        feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "        if i==1 :\n",
    "            feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "        else:\n",
    "            feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "    print(j)\n",
    "    if j == 1:\n",
    "        sample_space_5=feature_sequence\n",
    "    else:\n",
    "        sample_space_5=np.concatenate((sample_space_5,feature_sequence))\n",
    "    if j==9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 2622)\n",
      "(9, 11, 2622)\n",
      "(36, 11, 2622)\n"
     ]
    }
   ],
   "source": [
    "print(sample_space_5.shape)\n",
    "sample_space_6= sample_space_5.reshape(9,len(lcolourFolder),feature_vector.shape[1])\n",
    "print(sample_space_6.shape)\n",
    "total_sample_space2=np.concatenate((total_sample_space1,sample_space_6))\n",
    "print(total_sample_space2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('x_train.npy',total_sample_space2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#import into \n",
    "y_train_1=np.ones((9,1,1))\n",
    "y_train_2=np.zeros((9,1,1))\n",
    "y_train=np.concatenate((y_train_1,y_train_2))\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(total_sample_space.shape[1],total_sample_space.shape[2])\n",
    "model.add(LSTM(units=10,return_sequences=True,input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=10,return_sequences=True,input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=10,return_sequences=True,input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=10,input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(total_sample_space,y_train,epochs=3,batch_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-737febbc159c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_sequence_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict_proba(feature_sequence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[0]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[0]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "j += 1\n",
    "utterFolder= '%s\\\\%s' % (wordFolder,lwordFolder[9])\n",
    "lutterFolder = os.listdir(utterFolder)\n",
    "#print(lutterFolder)\n",
    "colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "lcolourFolder = os.listdir(colourFolder)\n",
    "i=0\n",
    "for frame in lcolourFolder:\n",
    "    i += 1\n",
    "    image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "    im=Image.open(image)\n",
    "    im = im.resize((224,224))\n",
    "    feature_vector = features(featuremodel,im, transform=True)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "    if i==1 :\n",
    "        feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "    else:\n",
    "        feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = feature_sequence.reshape((1,11,2622))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[0]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[1]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "j += 1\n",
    "utterFolder= '%s\\\\%s' % (wordFolder,lwordFolder[9])\n",
    "lutterFolder = os.listdir(utterFolder)\n",
    "#print(lutterFolder)\n",
    "colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "lcolourFolder = os.listdir(colourFolder)\n",
    "i=0\n",
    "for frame in lcolourFolder:\n",
    "    i += 1\n",
    "    image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "    im=Image.open(image)\n",
    "    im = im.resize((224,224))\n",
    "    feature_vector = features(featuremodel,im, transform=True)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "    if i==1 :\n",
    "        feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "    else:\n",
    "        feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = feature_sequence.reshape((1,11,2622))\n",
    "x_test3 = np.concatenate((x_test1,x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[6]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[0]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "j += 1\n",
    "utterFolder= '%s\\\\%s' % (wordFolder,lwordFolder[9])\n",
    "lutterFolder = os.listdir(utterFolder)\n",
    "#print(lutterFolder)\n",
    "colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "lcolourFolder = os.listdir(colourFolder)\n",
    "i=0\n",
    "for frame in lcolourFolder:\n",
    "    i += 1\n",
    "    image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "    im=Image.open(image)\n",
    "    im = im.resize((224,224))\n",
    "    feature_vector = features(featuremodel,im, transform=True)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "    if i==1 :\n",
    "        feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "    else:\n",
    "        feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test4 = feature_sequence.reshape((1,11,2622))\n",
    "x_test5 = np.concatenate((x_test3,x_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[10]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[2]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "j += 1\n",
    "utterFolder= '%s\\\\%s' % (wordFolder,lwordFolder[9])\n",
    "lutterFolder = os.listdir(utterFolder)\n",
    "#print(lutterFolder)\n",
    "colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "lcolourFolder = os.listdir(colourFolder)\n",
    "i=0\n",
    "for frame in lcolourFolder:\n",
    "    i += 1\n",
    "    image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "    im=Image.open(image)\n",
    "    im = im.resize((224,224))\n",
    "    feature_vector = features(featuremodel,im, transform=True)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "    if i==1 :\n",
    "        feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "    else:\n",
    "        feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test6 = feature_sequence.reshape((1,11,2622))\n",
    "x_test7 = np.concatenate((x_test5,x_test6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11, 2622)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample_space=[] #for appending different utterances\n",
    "feature_sequence = [] # for appending different timesteps\n",
    "inpDir='C:\\\\Users\\\\Om\\\\Desktop\\\\Dataset' #input dataset\n",
    "person = {}\n",
    "linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "#print(linpDir)\n",
    "personStr= linpDir[0]\n",
    "personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "lpersonFolder = os.listdir(personFolder)\n",
    "#print(lpersonFolder)\n",
    "wordID= lpersonFolder[3]\n",
    "wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "lwordFolder = os.listdir(wordFolder)\n",
    "#print(lwordFolder)\n",
    "j=0\n",
    "j += 1\n",
    "utterFolder= '%s\\\\%s' % (wordFolder,lwordFolder[0])\n",
    "lutterFolder = os.listdir(utterFolder)\n",
    "#print(lutterFolder)\n",
    "colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "lcolourFolder = os.listdir(colourFolder)\n",
    "i=0\n",
    "for frame in lcolourFolder:\n",
    "    i += 1\n",
    "    image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "    im=Image.open(image)\n",
    "    im = im.resize((224,224))\n",
    "    feature_vector = features(featuremodel,im, transform=True)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector= feature_vector.reshape((1,len(feature_vector)))\n",
    "    if i==1 :\n",
    "        feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "    else:\n",
    "        feature_sequence = np.concatenate((feature_sequence,feature_vector))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test8=feature_sequence.reshape((1,11,2622))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('x_test_4.npy',x_test8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
